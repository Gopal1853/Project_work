{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "vi1oF5Ex9ACi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('endata.txt', 'r') as text_file:\n",
        "    eng_sent = text_file.readlines()\n",
        "eng_sent = [sent.replace('\\n','') for sent in eng_sent]"
      ],
      "metadata": {
        "id": "b6Rxo16MQXDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('rusdata.txt', 'r') as text_file:\n",
        "  ru_sent = text_file.readlines()"
      ],
      "metadata": {
        "id": "BxPsH2LumGa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ru_sent = [sent.replace('\\n','') for sent in ru_sent]"
      ],
      "metadata": {
        "id": "XAWIf-itbbX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'en':eng_sent,'ru':ru_sent})"
      ],
      "metadata": {
        "id": "z6GD6e1McEvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = df.iloc[:2643]\n",
        "training_list = []\n",
        "\n",
        "validation_data = df.iloc[2643:]\n",
        "validation_list = []"
      ],
      "metadata": {
        "id": "RRuUrfEQcOkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in training_data.iterrows():\n",
        "  temp_dict = {\n",
        "          'en': row.en,\n",
        "          'ru': row.ru\n",
        "      }\n",
        "  training_list.append(temp_dict)\n",
        "\n",
        "temp_dict_1 = {\n",
        "    'translation': training_list\n",
        "}\n",
        "\n",
        "for i, row in validation_data.iterrows():\n",
        "  temp_dict = {\n",
        "          'en': row.en,\n",
        "          'ru': row.ru\n",
        "      }\n",
        "  validation_list.append(temp_dict)\n",
        "\n",
        "temp_dict_2 = {\n",
        "    'translation': validation_list\n",
        "}"
      ],
      "metadata": {
        "id": "fLwEl1Odc3IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = {}\n",
        "training_dataset['train'] = temp_dict_1\n",
        "training_dataset['validation'] = temp_dict_2"
      ],
      "metadata": {
        "id": "P8KghGcUdzjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-ru\"\n",
        "translator = pipeline(\"translation\", model=model_checkpoint)\n",
        "translator(\"this is a test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJcpn6IR6ISa",
        "outputId": "fdcaf9b6-fef6-446d-87e4-604fab802133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Это тест.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacremoses"
      ],
      "metadata": {
        "id": "c84p1Vhi6NOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-ru\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "e9vXQYiR6wHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[\"ru\"] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
        "    )\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "b5UfghSz7WPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_validation_list = []\n",
        "tokenized_train_list = []\n",
        "tokenized_datasets = {}\n",
        "\n",
        "validation_function_output = preprocess_function(training_dataset['validation'])\n",
        "training_function_output = preprocess_function(training_dataset['train'])"
      ],
      "metadata": {
        "id": "IV03Q61KfdUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(validation_function_output['input_ids'])):\n",
        "  temp_dict = {\n",
        "      'input_ids' : validation_function_output['input_ids'][i],\n",
        "      'attention_mask': validation_function_output['attention_mask'][i],\n",
        "      'labels': validation_function_output['labels'][i]\n",
        "  }\n",
        "  tokenized_validation_list.append(temp_dict)\n",
        "\n",
        "for i in range(len(training_function_output['input_ids'])):\n",
        "  temp_dict = {\n",
        "      'input_ids' : training_function_output['input_ids'][i],\n",
        "      'attention_mask': training_function_output['attention_mask'][i],\n",
        "      'labels': training_function_output['labels'][i]\n",
        "  }\n",
        "  tokenized_train_list.append(temp_dict)"
      ],
      "metadata": {
        "id": "TlYHl5_Nilx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['validation'] = tokenized_validation_list\n",
        "tokenized_datasets['train'] = tokenized_train_list"
      ],
      "metadata": {
        "id": "DsGJl_0NjkuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train'][0]"
      ],
      "metadata": {
        "id": "zfHpDUihfQ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning of the model"
      ],
      "metadata": {
        "id": "jhsV4ccJ84NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "ulhfA7-l8cti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "7YvWxo9K9IbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
        "batch.keys()"
      ],
      "metadata": {
        "id": "mjOccL6x9M47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"labels\"]"
      ],
      "metadata": {
        "id": "jG-GEZrV9Qj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"decoder_input_ids\"]"
      ],
      "metadata": {
        "id": "jL2G_idP9VSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 3):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ],
      "metadata": {
        "id": "mol2CEiF9Yq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "dowUHO0I9buB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "id": "EOo67iI7-nJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "F11ECDHP-rs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # In case the model returns more than the prediction logits\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100s in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "kn_PT2cU-_wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "hMMBEU4BB1qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch]"
      ],
      "metadata": {
        "id": "MlHEMsxpDfKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "HfJf7aJGDz_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"Gopal-finetuned-custom-en-to-ru\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=200,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "IS4qQOT5D4yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "KwWoKjhZEAc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "QzeR7RDwH27V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ],
      "metadata": {
        "id": "2BcBr8iDID5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "PeAZ3bBdIG7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")"
      ],
      "metadata": {
        "id": "E5aCzmOT4v0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ],
      "metadata": {
        "id": "EjFa1RMrFvrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}